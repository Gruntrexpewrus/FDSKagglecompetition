{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import All necessary library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First read all the final datasets for training and test data that have been generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"worked_data_train.csv\", index_col = 0)\n",
    "Test = pd.read_csv(\"worked_data_test.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute object columns with mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in train_data.select_dtypes(\"object\").columns:\n",
    "    train_data[feature].fillna(train_data[feature].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we impute the float and integer columns in train dataset with mean and median respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.get_dummies(train_data)\n",
    "for feature in train_data.select_dtypes(\"float64\").columns:\n",
    "    train_data[feature].fillna(train_data[feature].mean(), inplace = True)\n",
    "    \n",
    "for feature in train_data.select_dtypes(\"int64\").columns:\n",
    "    train_data[feature].fillna(train_data[feature].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same thing for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test =  pd.get_dummies(Test)\n",
    "for feature in Test.select_dtypes(\"float64\").columns:\n",
    "    Test[feature].fillna(train_data[feature].mean(), inplace = True)\n",
    "    \n",
    "for feature in Test.select_dtypes(\"int64\").columns:\n",
    "    Test[feature].fillna(train_data[feature].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there are any columns that is not contained in test dataset except the Target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(y,x):\n",
    "    for i in x:\n",
    "        if i not in y:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET\n",
      "CODE_GENDER_XNA\n",
      "NAME_INCOME_TYPE_Maternity leave\n",
      "NAME_FAMILY_STATUS_Unknown\n"
     ]
    }
   ],
   "source": [
    "fun(Test,train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the unatched columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(['CODE_GENDER_XNA', 'NAME_INCOME_TYPE_Maternity leave', 'NAME_FAMILY_STATUS_Unknown'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 450)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training our model, we use cross validation in order to perform better learning. For this purpose, we set the number of fold to 10. and by the end we get the foldsof the cross validation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cross_val(dataset)\n",
    "    k_fold = KFold(n_splits = 10, random_state = 42, shuffle = True)\n",
    "    result = []\n",
    "    for train_index, test_index in k_fold.split(dataset):\n",
    "        to_append = {\"Train\" : dataset.iloc[train_index,], \"Test\" : dataset.iloc[test_index]}\n",
    "        result.append(to_append)\n",
    "    return result\n",
    "\n",
    "# Run the function\n",
    "folds = get_cross_val(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to perform logistic regression and XgBoost and compare the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Logistic regression, we set the parameter C to 0.001, fit the model, get the probabilities, and finally check the ROC score for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey\n",
      "Hey\n",
      "Hey\n",
      "Hey\n",
      "Hey\n",
      "Hey\n",
      "Hey\n",
      "Hey\n",
      "Hey\n",
      "Hey\n"
     ]
    }
   ],
   "source": [
    "def logisticRegression(data):\n",
    "    roc_scores = []\n",
    "    for fold in folds:\n",
    "        log_reg = LogisticRegression(C = 0.0001)\n",
    "        log_reg.fit(fold[\"Train\"].drop([\"TARGET\"], axis = 1), fold[\"Train\"][\"TARGET\"])\n",
    "        probabilities = log_reg.predict_proba(fold[\"Test\"].drop([\"TARGET\"], axis = 1))\n",
    "        roc_scores.append(roc_auc_score(fold[\"Test\"][\"TARGET\"], probabilities[:, 1]))\n",
    "    return print(sum(roc_scores) / len(roc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6166448087998891"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegression(folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run the model for the test dataset, and get the csv of predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_or= pd.read_csv(\"application_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResult (model, data):\n",
    "    result = data['SK_ID_CURR']\n",
    "    P = model.predict_proba(Test)\n",
    "    preds = pd.DataFrame()\n",
    "    preds['SK_ID_CURR'] = result\n",
    "    l = []\n",
    "    for i in P:\n",
    "        l.append(i[1])\n",
    "    preds['TARGET'] = l\n",
    "    name = str(model) + '.csv'\n",
    "    preds.to_csv(name, index = False)\n",
    "\n",
    "#Run the program\n",
    "getResult(log_res, Test_or)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we try for XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey\n",
      "Hey\n",
      "Hey\n",
      "Hey\n",
      "Hey\n",
      "Hey\n",
      "Hey\n",
      "Hey\n",
      "Hey\n",
      "Hey\n"
     ]
    }
   ],
   "source": [
    "def XGBoost (data)\n",
    "    roc_scores_xg = []\n",
    "    for fold in data:\n",
    "        xg = XGBClassifier()\n",
    "        xg.fit(fold[\"Train\"].drop([\"TARGET\"], axis = 1), fold[\"Train\"][\"TARGET\"])\n",
    "        probabilities = xg.predict_proba(fold[\"Test\"].drop([\"TARGET\"], axis = 1))\n",
    "        roc_scores_xg.append(roc_auc_score(fold[\"Test\"][\"TARGET\"], probabilities[:, 1]))\n",
    "    return print (sum(roc_scores_xg) / len(roc_scores_xg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7658449900783483"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBoost(folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run the model for the test dataset, and get the csv of predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_xg = Test_or['SK_ID_CURR']\n",
    "P = xg.predict_proba(Test)\n",
    "preds = pd.DataFrame()\n",
    "preds['SK_ID_CURR'] = result_xg\n",
    "l = []\n",
    "for i in P:\n",
    "    l.append(i[1])\n",
    "preds['TARGET'] = l\n",
    "preds.to_csv('xg2.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
